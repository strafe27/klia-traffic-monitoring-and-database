{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ce88bef-3046-418f-b3cc-ec282f6a2e6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pytz\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import Row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8d9b8ce-1902-454f-96f6-afc24e0323a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = 'insert your api'\n",
    "BASE_URL = 'https://aeroapi.flightaware.com/aeroapi'\n",
    "\n",
    "headers = {\n",
    "    'x-apikey': API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dbacbb1-18e5-49a8-9436-955e5fb0a1f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-05T09:00:00\n",
      "2024-09-05T10:00:00\n"
     ]
    }
   ],
   "source": [
    "# Define Malaysia's timezone\n",
    "malaysia_tz = pytz.timezone('Asia/Kuala_Lumpur')\n",
    "\n",
    "# Get the current time in Malaysia\n",
    "malaysia_time = datetime.now(malaysia_tz)\n",
    "\n",
    "# Subtract one and two hours\n",
    "malaysia_time_minus_one_hour = malaysia_time - timedelta(hours=1)\n",
    "malaysia_time_minus_two_hour = malaysia_time - timedelta(hours=2)\n",
    "\n",
    "# Format the time in the desired format\n",
    "end_time_myt = malaysia_time_minus_one_hour.strftime('%Y-%m-%dT%H:00:00')\n",
    "start_time_myt = malaysia_time_minus_two_hour.strftime('%Y-%m-%dT%H:00:00')\n",
    "\n",
    "airport_code = 'WMKK'\n",
    "\n",
    "print(start_time_myt)\n",
    "print(end_time_myt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0ed35cc-bfd1-4c14-8988-4aed2e31945e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "TRANSFORMATION DEPARTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df48775e-bd62-4a5a-a484-7b0d0f33d148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+-----------------------+--------------------+------------------+--------------------+----------------+\n",
      "|flight_id|flight_number|aircraft_type|scheduled_departure_myt|actual_departure_myt|            origin|         destination|gate_destination|\n",
      "+---------+-------------+-------------+-----------------------+--------------------+------------------+--------------------+----------------+\n",
      "|   MAS740|          740|        B738 |    2024-09-05 09:20:00| 2024-09-05 09:58:07|Kuala Lumpur Int'l|        Yangon Int'l|            NULL|\n",
      "|  MAS2610|         2610|        B38M |    2024-09-05 09:25:00| 2024-09-05 09:56:39|Kuala Lumpur Int'l| Kota Kinabalu Int'l|            NULL|\n",
      "|  MAS2574|         2574|        B738 |    2024-09-05 09:05:00| 2024-09-05 09:54:44|Kuala Lumpur Int'l|                Miri|            NULL|\n",
      "|   XAX378|          378|        A333 |    2024-09-05 09:40:00| 2024-09-05 09:54:14|Kuala Lumpur Int'l|Taiwan Taoyuan Int'l|              B5|\n",
      "|    MAS72|           72|        B738 |    2024-09-05 09:20:00| 2024-09-05 09:51:32|Kuala Lumpur Int'l|     Hong Kong Int'l|            NULL|\n",
      "|   MAS754|          754|        B38M |    2024-09-05 09:10:00| 2024-09-05 09:49:23|Kuala Lumpur Int'l|Phnom Penh Int'l ...|            NULL|\n",
      "|   AXM707|          707|        A20N |    2024-09-05 09:50:00| 2024-09-05 09:49:17|Kuala Lumpur Int'l|    Singapore Changi|              G8|\n",
      "|   OMA822|          822|        B789 |    2024-09-05 09:40:00| 2024-09-05 09:46:56|Kuala Lumpur Int'l|          Seeb Int'l|            NULL|\n",
      "|   MAS366|          366|        A333 |    2024-09-05 09:25:00| 2024-09-05 09:45:22|Kuala Lumpur Int'l|Taiwan Taoyuan Int'l|              A5|\n",
      "|   XAX798|          798|        A333 |    2024-09-05 09:40:00| 2024-09-05 09:45:02|Kuala Lumpur Int'l|Ngurah Rai/Bali Intl|            NULL|\n",
      "|  AXM5204|         5204|        A320 |    2024-09-05 09:25:00| 2024-09-05 09:43:37|Kuala Lumpur Int'l|       Kuching Int'l|            NULL|\n",
      "|   MAS786|          786|        B738 |    2024-09-05 09:20:00| 2024-09-05 09:41:43|Kuala Lumpur Int'l|        Phuket Int'l|            NULL|\n",
      "|   MAS102|          102|        B738 |    2024-09-05 09:20:00| 2024-09-05 09:38:36|Kuala Lumpur Int'l|Shahjalal Interna...|            NULL|\n",
      "|   MAS784|          784|        B38M |    2024-09-05 09:10:00| 2024-09-05 09:36:59|Kuala Lumpur Int'l|Suvarnabhumi Bang...|            NULL|\n",
      "|   MAS750|          750|        B738 |    2024-09-05 09:10:00| 2024-09-05 09:35:26|Kuala Lumpur Int'l|  Tan Son Nhat Int'l|            NULL|\n",
      "|  AXM6118|         6118|        A320 |    2024-09-05 09:30:00| 2024-09-05 09:34:59|Kuala Lumpur Int'l|        Penang Int'l|            NULL|\n",
      "|   MAS715|          715|        A332 |    2024-09-05 09:10:00| 2024-09-05 09:33:08|Kuala Lumpur Int'l|Ngurah Rai/Bali Intl|            NULL|\n",
      "|   MAS125|          125|        B738 |    2024-09-05 09:05:00| 2024-09-05 09:31:00|Kuala Lumpur Int'l|         Perth Int'l|            NULL|\n",
      "|  AXM5136|         5136|        A320 |    2024-09-05 09:25:00| 2024-09-05 09:29:21|Kuala Lumpur Int'l| Kota Kinabalu Int'l|            NULL|\n",
      "|   MAS172|          172|        B738 |    2024-09-05 09:10:00| 2024-09-05 09:27:52|Kuala Lumpur Int'l| Indira Gandhi Int'l|            NULL|\n",
      "+---------+-------------+-------------+-----------------------+--------------------+------------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Replace problematic characters with underscores\n",
    "    return filename.replace(':', '_')\n",
    "\n",
    "def convert_myt_to_utc(myt_time_str):\n",
    "    myt_time = datetime.strptime(myt_time_str, '%Y-%m-%dT%H:%M:%S')\n",
    "    utc_time = myt_time - timedelta(hours=8)\n",
    "    return utc_time.isoformat()\n",
    "\n",
    "def convert_utc_to_myt(utc_time_str):\n",
    "    # Handle missing or invalid date strings\n",
    "    if utc_time_str and utc_time_str != 'N/A':\n",
    "        try:\n",
    "            utc_time = datetime.strptime(utc_time_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "            myt_time = utc_time + timedelta(hours=8)\n",
    "            return myt_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except ValueError:\n",
    "            return 'Invalid Date'\n",
    "    else:\n",
    "        return 'N/A'\n",
    "\n",
    "def get_recent_departures(airport_code, start_time_myt, end_time_myt):\n",
    "    start_time_iso = convert_myt_to_utc(start_time_myt) + 'Z'\n",
    "    end_time_iso = convert_myt_to_utc(end_time_myt) + 'Z'\n",
    "    \n",
    "    endpoint = f'{BASE_URL}/airports/{airport_code}/flights/departures'\n",
    "    params = {\n",
    "        'start': start_time_iso,\n",
    "        'end': end_time_iso,\n",
    "        'max_pages':10\n",
    "    }\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response.text\n",
    "\n",
    "def convert_to_dataframe_departures(spark, data):\n",
    "    # Define the schema explicitly\n",
    "    schema = StructType([\n",
    "        StructField(\"flight_id\", StringType(), True),\n",
    "        StructField(\"flight_number\", StringType(), True),\n",
    "        StructField(\"aircraft_type\", StringType(), True),\n",
    "        StructField(\"scheduled_departure_myt\", StringType(), True),\n",
    "        StructField(\"actual_departure_myt\", StringType(), True),\n",
    "        StructField(\"origin\", StringType(), True),\n",
    "        StructField(\"destination\", StringType(), True),\n",
    "        StructField(\"gate_destination\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create a list of Row objects with safe checks for None\n",
    "    rows = [\n",
    "        Row(\n",
    "            flight_id=flight.get('ident', 'N/A'),\n",
    "            flight_number=flight.get('flight_number', 'N/A'),\n",
    "            aircraft_type=flight.get('aircraft_type', 'N/A'),\n",
    "            scheduled_departure_myt=convert_utc_to_myt(flight.get('scheduled_off', 'N/A')),\n",
    "            actual_departure_myt=convert_utc_to_myt(flight.get('actual_off', 'N/A')),\n",
    "            origin=flight.get('origin', {}).get('name', 'N/A') if flight.get('origin') else 'N/A',\n",
    "            destination=flight.get('destination', {}).get('name', 'N/A') if flight.get('destination') else 'N/A',\n",
    "            gate_destination=flight.get('gate_destination', 'N/A')\n",
    "        )\n",
    "        for flight in data.get('departures', [])\n",
    "    ]\n",
    "    \n",
    "    # Convert the list of Rows into a DataFrame with the predefined schema\n",
    "    df = spark.createDataFrame(rows, schema=schema)\n",
    "    return df\n",
    "\n",
    "# Fetch recent departures\n",
    "recent_departures = get_recent_departures(airport_code, start_time_myt, end_time_myt)\n",
    "\n",
    "# Check if the data is in JSON format\n",
    "if isinstance(recent_departures, dict):\n",
    "    df_departures = convert_to_dataframe_departures(spark, recent_departures)\n",
    "    df_departures.show()  # Display the DataFrame\n",
    "else:\n",
    "    print(\"Error fetching data:\", recent_departures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe74d1f8-7cfd-42dc-9afb-84f0fa52e693",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "departure_row = df_departures.count()\n",
    "print(departure_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b36fe3b-205e-4ac7-9a77-051db19ec61d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "SAVE FILES DEPARTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "727c18ca-71ce-422d-955c-eb14afec8e3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sanitize the start time for use in filenames and paths (if needed)\n",
    "sanitized_start_time = sanitize_filename(start_time_myt)\n",
    "\n",
    "# Define the folder path before writing the file (no need for dynamic subdirectories)\n",
    "folder_path_departures = '/mnt/raw/departures/'\n",
    "\n",
    "# Coalesce the DataFrame to a single partition\n",
    "df_departures_coalesced = df_departures.coalesce(1)\n",
    "\n",
    "# Append a unique timestamp or identifier to the file name to avoid overwriting\n",
    "unique_identifier = sanitized_start_time  # You can use the start time or any unique ID\n",
    "\n",
    "# Write the coalesced DataFrame to a Parquet file directly in the /mnt/raw/departures/ folder\n",
    "df_departures_coalesced.write.mode('append').parquet(folder_path_departures)\n",
    "\n",
    "# List the files in the directory after writing the Parquet file\n",
    "files_departures = dbutils.fs.ls(folder_path_departures)\n",
    "\n",
    "# Find the part file and rename it to the desired name with the sanitized start time and unique identifier\n",
    "corrected_file_path_departures = f\"{folder_path_departures}departures_{unique_identifier}.parquet\"\n",
    "\n",
    "# Loop through and handle the files\n",
    "for file in files_departures:\n",
    "    if file.name.startswith(\"part-\"):\n",
    "        # Move (rename) the part file to the desired file name\n",
    "        dbutils.fs.mv(file.path, corrected_file_path_departures)\n",
    "    elif file.name.startswith(\"_SUCCESS\") or file.name.startswith(\"_committed\") or file.name.startswith(\"_started\"):\n",
    "        # Remove unwanted system files like _SUCCESS, _committed, _started\n",
    "        dbutils.fs.rm(file.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9af319-39f2-45f3-b1bb-0e309a67bd3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "TRANSFORMATION ARRIVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b500008-b6a4-40a6-bf83-585cf69d749a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-------------+---------------------+-------------------+--------------------+------------------+----------------+\n",
      "|flight_id|flight_number|aircraft_type|scheduled_arrival_myt| actual_arrival_myt|              origin|       destination|gate_destination|\n",
      "+---------+-------------+-------------+---------------------+-------------------+--------------------+------------------+----------------+\n",
      "|   MAS126|          126|        A333 |  2024-09-05 09:44:00|2024-09-05 09:57:31|         Perth Int'l|Kuala Lumpur Int'l|            NULL|\n",
      "|   AXM702|          702|        A21N |  2024-09-05 10:05:00|2024-09-05 09:57:19|    Singapore Changi|Kuala Lumpur Int'l|            NULL|\n",
      "|  AXM5205|         5205|        A320 |  2024-09-05 10:20:00|2024-09-05 09:52:10|       Kuching Int'l|Kuala Lumpur Int'l|            NULL|\n",
      "|   MAU646|          646|        A332 |  2024-09-05 10:00:00|2024-09-05 09:50:49|Sir Seewoosagur R...|Kuala Lumpur Int'l|             C12|\n",
      "|   AWQ550|          550|        A320 |  2024-09-05 09:50:00|2024-09-05 09:47:34|Ngurah Rai/Bali Intl|Kuala Lumpur Int'l|            NULL|\n",
      "|  AXM6021|         6021|        A320 |  2024-09-05 09:54:00|2024-09-05 09:42:46|  Sultan Abdul Halim|Kuala Lumpur Int'l|            NULL|\n",
      "|  MAS1038|         1038|        B738 |  2024-09-05 09:53:00|2024-09-05 09:40:39|Senai Int'l (Sult...|Kuala Lumpur Int'l|              B9|\n",
      "|  AXM6143|         6143|        A320 |  2024-09-05 09:38:00|2024-09-05 09:33:10|        Penang Int'l|Kuala Lumpur Int'l|            NULL|\n",
      "|   AWQ202|          202|        A320 |  2024-09-05 09:30:00|2024-09-05 09:29:46|Jakarta-Soekarno-...|Kuala Lumpur Int'l|            NULL|\n",
      "|   SIA106|          106|        A359 |  2024-09-05 09:41:00|2024-09-05 09:22:34|    Singapore Changi|Kuala Lumpur Int'l|             C14|\n",
      "|  MAS5091|         5091|        A333 |  2024-09-05 10:05:21|2024-09-05 09:20:21|  Kuala Lumpur Int'l|Kuala Lumpur Int'l|            NULL|\n",
      "|  AXM6225|         6225|        A320 |  2024-09-05 09:37:00|2024-09-05 09:18:56| Sultan Mahmud Int'l|Kuala Lumpur Int'l|            NULL|\n",
      "|  MAS2603|         2603|        B738 |  2024-09-05 09:35:00|2024-09-05 09:17:25| Kota Kinabalu Int'l|Kuala Lumpur Int'l|              A2|\n",
      "|  AXM9029|         9029|        A320 |  2024-09-05 09:25:00|2024-09-05 09:13:36|Senai Int'l (Sult...|Kuala Lumpur Int'l|            NULL|\n",
      "+---------+-------------+-------------+---------------------+-------------------+--------------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_recent_arrivals(airport_code, start_time_myt, end_time_myt):\n",
    "    end_time_iso = convert_myt_to_utc(end_time_myt) + 'Z'\n",
    "    start_time_iso = convert_myt_to_utc(start_time_myt) + 'Z'\n",
    "    \n",
    "    endpoint = f'{BASE_URL}/airports/{airport_code}/flights/arrivals'\n",
    "    params = {\n",
    "        'start': start_time_iso,\n",
    "        'end': end_time_iso,\n",
    "        'max_pages':10\n",
    "    }\n",
    "    \n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response.text\n",
    "\n",
    "def convert_to_dataframe_arrivals(spark, data):\n",
    "    # Define the schema explicitly for arrivals\n",
    "    schema = StructType([\n",
    "        StructField(\"flight_id\", StringType(), True),\n",
    "        StructField(\"flight_number\", StringType(), True),\n",
    "        StructField(\"aircraft_type\", StringType(), True),\n",
    "        StructField(\"scheduled_arrival_myt\", StringType(), True),\n",
    "        StructField(\"actual_arrival_myt\", StringType(), True),\n",
    "        StructField(\"origin\", StringType(), True),\n",
    "        StructField(\"destination\", StringType(), True),\n",
    "        StructField(\"gate_destination\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create a list of Row objects\n",
    "    rows = [\n",
    "        Row(\n",
    "            flight_id=flight.get('ident', 'N/A'),\n",
    "            flight_number=flight.get('flight_number', 'N/A'),\n",
    "            aircraft_type=flight.get('aircraft_type', 'N/A'),\n",
    "            scheduled_arrival_myt=convert_utc_to_myt(flight.get('scheduled_on', 'N/A')),\n",
    "            actual_arrival_myt=convert_utc_to_myt(flight.get('actual_on', 'N/A')),\n",
    "            origin=flight.get('origin', {}).get('name', 'N/A'),\n",
    "            destination=flight.get('destination', {}).get('name', 'N/A'),\n",
    "            gate_destination=flight.get('gate_destination', 'N/A')\n",
    "        )\n",
    "        for flight in data.get('arrivals', [])\n",
    "    ]\n",
    "    \n",
    "    # Convert the list of Rows into a DataFrame with the predefined schema\n",
    "    df = spark.createDataFrame(rows, schema=schema)\n",
    "    return df\n",
    "\n",
    "# Fetch recent arrivals\n",
    "recent_arrivals = get_recent_arrivals(airport_code, start_time_myt, end_time_myt)\n",
    "\n",
    "# Check if the data is in JSON format\n",
    "if isinstance(recent_arrivals, dict):\n",
    "    df_arrivals = convert_to_dataframe_arrivals(spark, recent_arrivals)\n",
    "    df_arrivals.show()  # Display the DataFrame\n",
    "else:\n",
    "    print(\"Error fetching data:\", recent_arrivals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0778ad3f-25ef-416f-9b3d-ce76c549a19b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "SAVE FILES ARRIVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81c045e0-adcf-4d95-81ca-74b8dd5224e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sanitize the start time for use in filenames and paths (if needed)\n",
    "sanitized_start_time = sanitize_filename(start_time_myt)\n",
    "\n",
    "# Define the folder path before writing the file (no need for dynamic subdirectories)\n",
    "folder_path_arrivals = '/mnt/raw/arrivals/'\n",
    "\n",
    "# Coalesce the DataFrame to a single partition\n",
    "df_arrivals_coalesced = df_arrivals.coalesce(1)\n",
    "\n",
    "# Append a unique timestamp or identifier to the file name to avoid overwriting\n",
    "unique_identifier = sanitized_start_time  # You can use the start time or any unique ID\n",
    "\n",
    "# Write the coalesced DataFrame to a Parquet file directly in the /mnt/raw/arrivals/ folder\n",
    "df_arrivals_coalesced.write.mode('append').parquet(folder_path_arrivals)\n",
    "\n",
    "# List the files in the directory after writing the Parquet file\n",
    "files_arrivals = dbutils.fs.ls(folder_path_arrivals)\n",
    "\n",
    "# Find the part file and rename it to the desired name with the sanitized start time and unique identifier\n",
    "corrected_file_path_arrivals = f\"{folder_path_arrivals}arrivals_{unique_identifier}.parquet\"\n",
    "\n",
    "# Loop through and handle the files\n",
    "for file in files_arrivals:\n",
    "    if file.name.startswith(\"part-\"):\n",
    "        # Move (rename) the part file to the desired file name\n",
    "        dbutils.fs.mv(file.path, corrected_file_path_arrivals)\n",
    "    elif file.name.startswith(\"_SUCCESS\") or file.name.startswith(\"_committed\") or file.name.startswith(\"_started\"):\n",
    "        # Remove unwanted system files like _SUCCESS, _committed, _started\n",
    "        dbutils.fs.rm(file.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16bacb04-31f6-418b-a0d0-5d410e6310d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "departure_row = df_departures.count()\n",
    "arrival_row = df_arrivals.count()\n",
    "print(arrival_row)\n",
    "print(departure_row)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "api to hourly",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
